{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chunking\n",
    "\n",
    "LLM의 context window의 한계 때문에 chunking이 필요하지만 chunking을 하기전에 고려할 사항들이 있습니다. [Reference](https://www.pinecone.io/learn/chunking-strategies/)\n",
    "\n",
    "1.Document Structure & Length\n",
    "\n",
    " - Long (Book, academic articles, ...) or Short (Social Media post, reviews, ...)\n",
    " - Format (html, markdown, pdf, ...)\n",
    "\n",
    "\n",
    "sentence로 embedding을 할 경우에는 sentense자체의 구체적 의미에 집중하는 embedding이기 때문에 단락이나 문서에서 찾을 수 있는 더 넓은 문맥 정보를 놓칠 수 있음. 반대로 document형태로 전체단락을 embedding하는 경우 전반적인 맥락과 텍스트 내의 문장 및 구문 간의 관계를 모두 고려하는 더 포괄적인 vector representation이 얻어지며 텍스트의 보다 넓은 의미와 주제를 포함되지만 큰 입력 텍스트 크기는 개별 문장이나 구문의 중요성을 희석시킬 수 있으며, 인덱스를 쿼리할 때 정확한 일치를 찾기 어렵게 만들 수 있습니다.\n",
    "\n",
    "2.Embedding Model:\n",
    "\n",
    " - Chunk size가 어떤 embedding 모델을 사용할지를 결정하기 때문에 중요합니다.\n",
    " - Sentence-Transformer (개별문장에서 잘동작) vs OpenAI \"text-embedding-ada-002\" (256 or 512개의 token chunk)\n",
    "\n",
    "3.Expected Queries:\n",
    " - 사용자의 query가 짧고 구체적일지? 아니면 길고 복잡할지?\n",
    "\n",
    "4.Top-K retrieve\n",
    " - retrieve를 많이 할 수록 token의 갯수가 증가하여 inference time과 memory 소모가 커짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking Methods\n",
    "\n",
    "1.Fixed-size chunking\n",
    "\n",
    "2.Content-aware Chunking\n",
    " - Sentence splitting\n",
    "    - Naive splitting\n",
    "    ```python\n",
    "    # based on number of characters\n",
    "    from langchanin.text_spliter import CharacterTextSplitter\n",
    "    splitter = CharacterTextSplitter(\n",
    "      chunk_size=100,\n",
    "      chunk_overlap=10,\n",
    "      seperator='\\n\\n'\n",
    "    )\n",
    "\n",
    "    # based on sentences\n",
    "    chunks = text.split(\".\")\n",
    "    ```\n",
    "\n",
    "    - NLTK sentence splitting\n",
    "    ```python\n",
    "    from langchain.text_splitter import NLTKTextSplitter\n",
    "    splitter = NLTKSplitter()\n",
    "    chunks = splitter.split_text(text)\n",
    "    ```\n",
    "    - spaCy sentence splitting\n",
    "    ```python\n",
    "    from langchain.text_splitter import SpacyTextSplitter\n",
    "    splitter = SpacyTextSplitter()\n",
    "    chunks = splitter.split_text(text)\n",
    "    ```\n",
    " - Recursive Chunking\n",
    " - Specialized Chunking\n",
    "    - Markdown\n",
    "    - Latex\n",
    "    - HTML\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make document from crawling data\n",
    "\n",
    "Strategy\n",
    "\n",
    "1.question과 (accepted) answer를 concat하여 하나의 문단으로 만들어서 문서화 하고 이를 연결하여 저장합니다.\n",
    "\n",
    "2.answer만 사용하여 문서화하고 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "STACKEXCHANGE_API_KEY=os.environ.get('STACKEXCHANGE_API_KEY', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load crawled data\n",
    "concat_contents = []\n",
    "answer_contents = []\n",
    "question_contents = []\n",
    "\n",
    "for json_path in sorted(\n",
    "    glob.glob(\"../data/law_stackexchange/raw/*.json\"),\n",
    "    key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]),\n",
    "):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for question in data[\"items\"]:\n",
    "        # filter only answered questions\n",
    "        if question[\"is_answered\"] and question[\"answer_count\"] > 0:\n",
    "            question_content = (question[\"body\"] + \"\\n\" + question[\"title\"]).strip()\n",
    "            concat_content = (question[\"body\"] + \"\\n\" + question[\"title\"]).strip()\n",
    "            accepted_answer_id = question.get(\"accepted_answer_id\", None)\n",
    "            \n",
    "            # concat question with accepted answers\n",
    "            for answer in question[\"answers\"]:\n",
    "                if accepted_answer_id is not None and answer[\"answer_id\"] == accepted_answer_id:\n",
    "                    concat_content += \"\\n\" + answer[\"body\"].strip()\n",
    "                    answer_contents.append(answer[\"body\"].strip())\n",
    "                \n",
    "                elif int(answer[\"score\"]) >= 5:\n",
    "                    answer_contents.append(answer[\"body\"].strip())\n",
    "\n",
    "            concat_contents.append(concat_content.strip())\n",
    "            question_contents.append(question_content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25629, 17802, 25629)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concat_contents), len(answer_contents), len(question_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI model을 활용하여 summary를 db에 저장하는 방식?\n",
    "```python\n",
    "# summarize concat contents\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama, LlamaCpp\n",
    "from langchain_core.documents import Document\n",
    "# docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama:latest\n",
    "\n",
    "# Define prompt\n",
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "# prompt_template = \"\"\"Write a summary of the following:\n",
    "# \"{text}\"\n",
    "# SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Define LLM chain\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-1106\")\n",
    "# llm = Ollama(model=\"llama2\")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "# save summarized results one by one to keep track\n",
    "with open(\"../data/law_stackexchange/summarized.txt\", 'w') as f:\n",
    "    f.write('')\n",
    "failed_chunk_ids = []\n",
    "for chunk_idx, chunk in enumerate(tqdm(chunks)):\n",
    "    try:\n",
    "        content = stuff_chain.run([chunk])\n",
    "    except:\n",
    "        failed_chunk_ids.append(chunk_idx)\n",
    "        continue\n",
    "    with open(\"../data/law_stackexchange/summarized.txt\", 'a') as f:\n",
    "        f.write(content + '\\n\\n')\n",
    "# 2029 so far\n",
    "# summarized_chunks = [stuff_chain.run([chunk]) for chunk in tqdm(chunks)]\n",
    "# summarized_contents = '\\n\\n'.join([summarized_chunk.page_content for summarized_chunk in summarized_chunks])\n",
    "\n",
    "```\n",
    "\n",
    "markdown tag를 없애거나 추가적으로 pre processing을 하려고 시도하였으나 gpt를 이용해서 raw문서에서 바로 summarization을 하는 것이 더 좋다고 판단하였습니다... \n",
    "\n",
    "\n",
    "하지만 GPT가격이 비싸서 대략 전체 $15 ~ $20 정도 소요될 것으로 추정되어, opensource를 사용해보려하였으나 CPU version model의 속도가 현저히 떨어져서 그냥 raw data를 사용하기로 하였습니다\n",
    "\n",
    "[Ollama](https://github.com/ollama/ollama?tab=readme-ov-file) 홈페이지에서 Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = [Document(page_content=page_content) for page_content in concat_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000, # sentense transformer라 숫자를 낮춰야하지만 문맥을 고려한 벡터를 만들기 위해 높은 숫자를 사용\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "concat_chunks = text_splitter.create_documents(concat_contents)\n",
    "answer_chunks = text_splitter.create_documents(answer_contents)\n",
    "question_chunks = text_splitter.create_documents(question_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_chunks 30036\n",
      "answer_chunks 20326\n",
      "question_chunks 26135\n"
     ]
    }
   ],
   "source": [
    "print(\"concat_chunks\", len(concat_chunks))\n",
    "print(\"answer_chunks\", len(answer_chunks))\n",
    "print(\"question_chunks\", len(question_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Indexing\n",
    "\n",
    "그냥 raw document를 split하지않고 하나의 document로 openai embedding model로 embedding 진행하는 것 또한 비용이 많이 들어서\n",
    "기존 OpenAIEmbeddings 말고 sentence transformer를 이용하여 임베딩을 진행하였습니다. \n",
    "물론.. sentense transformer의 input이 여러개의 문장이 되어버려서 임베딩의 정확도가 떨어질 것으로 생각됩니다. \n",
    "하지만 생각보다 잘 동작하는 것 같습니다. \n",
    "\n",
    "아래는 gpt embedding모델을 사용하는 코드입니다.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# text-embedding-3-small is cheaper than text-embedding-ada-002, and performing well\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=os.environ.get('OPENAI_API_KEY'), model=\"text-embedding-3-small\")\n",
    "vectorstores = FAISS.from_documents(chunks, embeddings_model)\n",
    "vectorstores.save_local(\"faiss_index_law_stackexchange\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819b4b4261a1473c9ee04bc7b7e8d124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f35aeb6595642cb8d3e3b9527c8cc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed245662fa4fcb9870f6886334975a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e10751c40a4abf94f641b8ed3e4a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af395e931de640d1aa317f4097327c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7d810398324854925103e844093ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701426ed0b824546a3b5a910a4497181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2371d80d03e34c88be3644c9e806dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21981178d16e48acb831554ae1ce4784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09532c4d5ef540c5afca7b7f83cc1d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c4574e56124e5694fbf4fd55100d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open ../db/law_stackexchange/sentence_transformer/faiss_index_answer/index.faiss for reading: No such file or directory\n",
      "Failed to load FAISS index, creating new one..\n"
     ]
    }
   ],
   "source": [
    "# replace openAI embeddings to sentense transformer to save costs..\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "EMBEDDINGS_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=EMBEDDINGS_MODEL_NAME)\n",
    "\n",
    "for type, chunks in [ ('question', question_chunks), ('concat', concat_chunks), ('answer', answer_chunks)]:\n",
    "    DB_PATH = f\"../db/law_stackexchange/sentence_transformer/faiss_index_{type}\"\n",
    "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        vectorstores=FAISS.load_local(DB_PATH, embeddings_model)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Failed to load FAISS index, creating new one..\")\n",
    "        vectorstores = FAISS.from_documents(chunks, embeddings_model)\n",
    "        vectorstores.save_local(DB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code for retriving\n",
    "\n",
    "# retrived_docs = vectorstores.similarity_search(\"What is the difference between a contract and a deed?\", k=3)\n",
    "# retrived_docs_with_score = vectorstores.similarity_search_with_score(\"How can I Find the license for a widely-used photograph\", k=3)\n",
    "retrived_docs_with_score = vectorstores.similarity_search_with_score(\n",
    "    \"\"\"I'm contemplating the development of a music transcription service as a personal side project. Through this service, clients would have the option to commission me to transcribe a song or specific sections of a song in exchange for a fee. Following completion, I would provide the client with a PDF version of the transcription.\n",
    "As far as my understanding goes, distributing or selling any derivative work of a copyrighted song, including sheet music, is considered illegal. However, in the case of this service, my intention is not to publish or sell the sheet music; rather, I would create the transcription exclusively for the client who requested it in exchange for a fee.\n",
    "I am aware that it is legally permissible to transcribe a song for personal use if you have purchased the song yourself. However, I am uncertain about the legality when someone else pays for a transcription of a song they have purchased, with the understanding that they are the sole recipient of the transcription.\"\"\",\n",
    "      k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"<p>I'm considering creating a music transcription service as a side hobby project. With this service, clients could request that I transcribe a song (or parts of a song) for them in exchange for a fee. I would then send the client a PDF version of my transcription.</p>\\n\\n<p>From my understanding, it is illegal when you sell or give away any derivative form of a copyrighted song (including sheet music). With this service, I do not intend to publish or sell sheet music. I would merely create the transcription, and give it to the client that requested it for a fee. </p>\\n\\n<p>I understand it is perfectly legal to transcribe a song you purchased yourself, as long as it is for personal use. Does this become copyright infringement when someone else pays you to transcribe a song they've purchased, and this person is the only one who will get the transcription? </p>\\n\\nLegality of Music Transcription Service\"),\n",
       "  0.0892093),\n",
       " (Document(page_content=\"<p>I'm learning to play an instrument and I would like to transcribe the songs I heard for later practicing. I have some questions regarding transcribing music and the legality of using musical transcription:</p>\\n\\n<ol>\\n<li>Is it legal for me to transcribe a copyrighted song?</li>\\n<li>Do I need permission to sell or give away my musical transcriptions for free, in both when case the transcription may imitate the original sounds or is a recomposition of the songs.</li>\\n<li>Can I perform the transcription in public, and the performance may involving profits for myself (i.e selling tickets, crowd donation, selling performance recordings...)</li>\\n</ol>\\n\\nTranscribing music and the legality of using musical transcription\"),\n",
       "  0.48548475),\n",
       " (Document(page_content='<p>Let\\'s say I purchased a piece of sheet music in PDF form from the author\\'s website. I can\\'t find anything on their website about licensing restrictions for downloads. Let\\'s say I want to share the sheet music with other musicians at my church so that we can play it during the church service. [Edit: I do have permission to perform the song via <a href=\"https://us.ccli.com/copyright-license/\" rel=\"nofollow noreferrer\" title=\"CCLI\">CCLI</a>.]</p>\\n\\n<p>Am I allowed to share the electronic PDF with the musicians? Or the printed music? Or both/neither? Or is this a gray area?</p>\\n\\nSharing music PDF I purchased'),\n",
       "  0.68250513)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrived_docs_with_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "\n",
    "Evaluation을 위한 QA Set을 만드는 작업입니다. 아래 프롬프트를 이용해서 ChatBot Model을 이용하여 QA Set을 만듭니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2797/2487462641.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import wandb\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import QAGenerationChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate QA Eval Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templ = \"\"\"You are a smart assistant designed to come up with meaninful question and answer pair. The question should be to the point and the answer should be as detailed as possible.\n",
    "Given a piece of text, you must come up with a question and answer pair that can be used to evaluate a QA bot. Do not make up stuff. Stick to the text to come up with the question and answer pair.\n",
    "When coming up with this question/answer pair, you must respond in the following format:\n",
    "```\n",
    "{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}}\n",
    "```\n",
    "\n",
    "Everything between the ``` must be valid json.\n",
    "\n",
    "Please come up with a question/answer pair, in the specified JSON format, for the following text:\n",
    "----------------\n",
    "{text}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(templ)\n",
    "num_qa_pairs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Generate QA\n",
    "EVAL_QA_PAIRS_PATH = '../data/law_stackexchange/eval_qa_pairs.json'\n",
    "if not os.path.exists(EVAL_QA_PAIRS_PATH):\n",
    "    llm = ChatOpenAI(temperature=0.9)\n",
    "    chain = QAGenerationChain.from_llm(llm=llm, prompt=PROMPT)\n",
    "\n",
    "    random_chunks = []\n",
    "    for i in range(num_qa_pairs):\n",
    "        random_chunks.append(random.randint(0, len(concat_chunks))) # (5, 172)\n",
    "\n",
    "    print(\"random_chunks\", random_chunks)\n",
    "    eval_qa_pairs = []\n",
    "\n",
    "    for idx in random_chunks:\n",
    "        qa = chain.run(concat_chunks[idx].page_content)\n",
    "        eval_qa_pairs.extend(qa)\n",
    "\n",
    "    with open(EVAL_QA_PAIRS_PATH, 'w') as f:\n",
    "        json.dump(eval_qa_pairs, f, indent=4)\n",
    "else:\n",
    "    with open(EVAL_QA_PAIRS_PATH, 'r') as f:\n",
    "        eval_qa_pairs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Can a nation prevent another nation from issuing visas to its citizens?',\n",
       "  'answer': \"No, a nation cannot directly tell another nation to not grant a particular visa. However, a nation can require its citizens to obtain an exit permit or work permit, as exemplified by Nepal's requirement for citizens emigrating to the United States on an H-1B visa. This exit permit needs to be presented to immigration in order to leave the country. Imposing exit visas, though possible, is not common and is often associated with authoritarian regimes. It is important to note that imposing an exit visa may raise concerns or objections in western society.\"},\n",
       " {'question': 'What principles of sentencing are applied in Canada?',\n",
       "  'answer': 'In Canada, the declared purposes of sentencing do not include revenge. The purposes of sentencing, as listed in section 718 of the Criminal Code, are to denounce unlawful conduct and the harm done to victims or the community, to deter offenders and others from committing offenses, to separate offenders from society if necessary, to assist in rehabilitating offenders, to provide reparations for harm done to victims or the community, and to promote a sense of responsibility in offenders and acknowledgement of the harm done to victims or the community.'},\n",
       " {'question': \"According to the definition of a right, can a child in a developing country go to a private school or private hospital without paying any fee and tuition just because that's their right?\",\n",
       "  'answer': \"No, according to the definition of a right, a child in a developing country cannot go to a private school or private hospital without paying any fee and tuition just because that's their right. The concept of a right refers to a moral or legal entitlement to have or do something, but it does not necessarily guarantee the provision of that service or resource without any cost. In a developing country with limited infrastructure, including public schools and hospitals, it may be challenging for children to access these services, especially if they cannot afford the fees. While children have the right to primary education and good quality healthcare, the means of providing these services may vary depending on the country's resources and policies. In some cases, there may be government initiatives or subsidies to support children from low-income families, but it does not necessarily mean that private schools or hospitals would provide their services for free to all children.\"},\n",
       " {'question': 'How is Citymapper not breaking the Google Maps Terms of Service?',\n",
       "  'answer': 'Citymapper is not breaking the Google Maps Terms of Service because they have agreements with various companies and government entities, including Google, to access the data they use in their app. They state in their TOS that they use third parties like Google, Transport for London, Metropolitan Transport Authority, and others to provide data on which the transport information and recommendations in the app are based.'},\n",
       " {'question': 'Under what circumstances can a person use deadly physical force in Oregon?',\n",
       "  'answer': 'A person may use deadly physical force in Oregon in defense of another person as provided in ORS 161.219 (Limitations on use of deadly physical force in defense of a person), or when the person reasonably believes it necessary to prevent the commission of arson or a felony by force and violence by the trespasser. However, it is not legal to use deadly force in defense of property, as specified in ORS 161.229. Additionally, under ORS 161.215, one who provokes or is the aggressor in a confrontation may not use physical force and is not entitled to assert a right of self-defense.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qa_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=EMBEDDINGS_MODEL_NAME)\n",
    "faiss_db = FAISS.load_local(\n",
    "    f\"../db/law_stackexchange/sentence_transformer/faiss_index_answer\", embeddings_model\n",
    ")\n",
    "retriever = faiss_db.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, a nation cannot directly prevent another nation from issuing visas to its citizens. Each nation has sovereignty over its own immigration policies and can decide who to grant visas to. However, a nation can indirectly restrict its citizens from traveling to another country by implementing exit visas, as mentioned in the initial context. Exit visas require citizens to obtain permission from their own government before leaving the country. But it's worth noting that exit visas are not common and can be seen as limiting individual freedom.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"Can a nation prevent another nation from issuing visas to its citizens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can a nation prevent another nation from issuing visas to its citizens?\n",
      "What principles of sentencing are applied in Canada?\n",
      "According to the definition of a right, can a child in a developing country go to a private school or private hospital without paying any fee and tuition just because that's their right?\n",
      "How is Citymapper not breaking the Google Maps Terms of Service?\n",
      "Under what circumstances can a person use deadly physical force in Oregon?\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for qa_pair in eval_qa_pairs:\n",
    "    question = qa_pair[\"question\"]\n",
    "    print(question)\n",
    "    predictions.append({\"response\": qa.run(question)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "eval_chain = QAEvalChain.from_llm(llm = OpenAI(temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Can a nation prevent another nation from issuing visas to its citizens?',\n",
       "  'answer': \"No, a nation cannot directly tell another nation to not grant a particular visa. However, a nation can require its citizens to obtain an exit permit or work permit, as exemplified by Nepal's requirement for citizens emigrating to the United States on an H-1B visa. This exit permit needs to be presented to immigration in order to leave the country. Imposing exit visas, though possible, is not common and is often associated with authoritarian regimes. It is important to note that imposing an exit visa may raise concerns or objections in western society.\"},\n",
       " {'question': 'What principles of sentencing are applied in Canada?',\n",
       "  'answer': 'In Canada, the declared purposes of sentencing do not include revenge. The purposes of sentencing, as listed in section 718 of the Criminal Code, are to denounce unlawful conduct and the harm done to victims or the community, to deter offenders and others from committing offenses, to separate offenders from society if necessary, to assist in rehabilitating offenders, to provide reparations for harm done to victims or the community, and to promote a sense of responsibility in offenders and acknowledgement of the harm done to victims or the community.'},\n",
       " {'question': \"According to the definition of a right, can a child in a developing country go to a private school or private hospital without paying any fee and tuition just because that's their right?\",\n",
       "  'answer': \"No, according to the definition of a right, a child in a developing country cannot go to a private school or private hospital without paying any fee and tuition just because that's their right. The concept of a right refers to a moral or legal entitlement to have or do something, but it does not necessarily guarantee the provision of that service or resource without any cost. In a developing country with limited infrastructure, including public schools and hospitals, it may be challenging for children to access these services, especially if they cannot afford the fees. While children have the right to primary education and good quality healthcare, the means of providing these services may vary depending on the country's resources and policies. In some cases, there may be government initiatives or subsidies to support children from low-income families, but it does not necessarily mean that private schools or hospitals would provide their services for free to all children.\"},\n",
       " {'question': 'How is Citymapper not breaking the Google Maps Terms of Service?',\n",
       "  'answer': 'Citymapper is not breaking the Google Maps Terms of Service because they have agreements with various companies and government entities, including Google, to access the data they use in their app. They state in their TOS that they use third parties like Google, Transport for London, Metropolitan Transport Authority, and others to provide data on which the transport information and recommendations in the app are based.'},\n",
       " {'question': 'Under what circumstances can a person use deadly physical force in Oregon?',\n",
       "  'answer': 'A person may use deadly physical force in Oregon in defense of another person as provided in ORS 161.219 (Limitations on use of deadly physical force in defense of a person), or when the person reasonably believes it necessary to prevent the commission of arson or a felony by force and violence by the trespasser. However, it is not legal to use deadly force in defense of property, as specified in ORS 161.229. Additionally, under ORS 161.215, one who provokes or is the aggressor in a confrontation may not use physical force and is not entitled to assert a right of self-defense.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_outputs = eval_chain.evaluate(\n",
    "    eval_qa_pairs,\n",
    "    predictions,\n",
    "    question_key=\"question\",\n",
    "    answer_key=\"answer\",\n",
    "    prediction_key=\"response\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'results': ' CORRECT'},\n",
       " {'results': ' CORRECT'},\n",
       " {'results': ' CORRECT'},\n",
       " {'results': ' CORRECT'},\n",
       " {'results': ' CORRECT'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for graded_output in graded_outputs:\n",
    "    assert isinstance(graded_output, dict)\n",
    "    if graded_output[\"results\"].strip() == \"CORRECT\":\n",
    "        correct+=1\n",
    "\n",
    "correct/len(graded_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277ee69cc3164cb581b38b2b5242ca3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf13d4fe97b4c6792ede17936e60a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad_metric = load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"squad\", module_type: \"metric\", features: {'predictions': {'id': Value(dtype='string', id=None), 'prediction_text': Value(dtype='string', id=None)}, 'references': {'id': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}}, usage: \"\"\"\n",
       "Computes SQuAD scores (F1 and EM).\n",
       "Args:\n",
       "    predictions: List of question-answers dictionaries with the following key-values:\n",
       "        - 'id': id of the question-answer pair as given in the references (see below)\n",
       "        - 'prediction_text': the text of the answer\n",
       "    references: List of question-answers dictionaries with the following key-values:\n",
       "        - 'id': id of the question-answer pair (see above),\n",
       "        - 'answers': a Dict in the SQuAD dataset format\n",
       "            {\n",
       "                'text': list of possible texts for the answer, as a list of strings\n",
       "                'answer_start': list of start positions for the answer, as a list of ints\n",
       "            }\n",
       "            Note that answer_start values are not taken into account to compute the metric.\n",
       "Returns:\n",
       "    'exact_match': Exact match (the normalized answer exactly match the gold answer)\n",
       "    'f1': The F-score of predicted tokens versus the gold answer\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [{'prediction_text': '1976', 'id': '56e10a3be3433e1400422b22'}]\n",
       "    >>> references = [{'answers': {'answer_start': [97], 'text': ['1976']}, 'id': '56e10a3be3433e1400422b22'}]\n",
       "    >>> squad_metric = evaluate.load(\"squad\")\n",
       "    >>> results = squad_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'exact_match': 100.0, 'f1': 100.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data munging to get the examples in the right format\n",
    "for i, eg in enumerate(eval_qa_pairs):\n",
    "    eg[\"id\"] = str(i)\n",
    "    eg[\"answers\"] = {\"text\": [eg[\"answer\"]], \"answer_start\": [0]}\n",
    "    predictions[i][\"id\"] = str(i)\n",
    "    predictions[i][\"prediction_text\"] = predictions[i][\"response\"]\n",
    "\n",
    "for p in predictions:\n",
    "    del p[\"response\"]\n",
    "\n",
    "new_qa_pairs = eval_qa_pairs.copy()\n",
    "for eg in new_qa_pairs:\n",
    "    del eg[\"question\"]\n",
    "    del eg[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = squad_metric.compute(\n",
    "    references=[new_qa_pairs[1]],\n",
    "    predictions=[predictions[1]],\n",
    ") # can also get mean scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.0, 'f1': 60.416666666666664}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
